{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-SF-30 | Unit Project 1: Research Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A.  Evaluate the following problem statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"Determine which free-tier customers will covert to paying customers, using demographic data collected at signup (age, gender, location, and profession) and customer useage data (days since last log in, and `activity score 1 = active user`, `0 = inactive user`) based on Hooli data from January-April 2015.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 1.  What is the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Converted to paying customer or not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 2.  What are the predictors/covariates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Age, gender, location, profession, days since last log in, and activity score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 3.  What timeframe is this data relevent for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: January - April 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 4.  What is the hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Demographic and customer usage data can be used to predict whether a free-tier customer will convert to be a paying customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B.  Let's start exploring our UCLA dataset and answer some simple questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige\n",
       "0      0  380.0  3.61       3.0\n",
       "1      1  660.0  3.67       3.0\n",
       "2      1  800.0  4.00       1.0\n",
       "3      1  640.0  3.19       4.0\n",
       "4      0  520.0  2.93       4.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(os.path.join('..', '..', 'dataset', 'dataset-ucla-admissions.csv'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 5.  Create a data dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Variable | Description | Type of Variable\n",
    "---|---|---\n",
    "GRE score | Score on Graduate Record Examination, integer from 0 to 800 | Continuous\n",
    "GPA score | Grade Point Average, number from 0 to 4.0 | Continuous\n",
    "prestige | Integer score from 1 (highest prestige) to 4 (lowest) | Categorical\n",
    "admit | binary, 1 = admitted, 0 = rejected | Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to explore the association between Admission decision and the above academic record data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 6.  What is the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Admission decision (`1` for admitted, `0` for denied admission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 7.  What are the predictors/covariates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: GRE (Graduate Record Examination) score, GPA (Grade Point Average) score, and prestige of alma mater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 8.  What timeframe is this data relevent for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The data is hypothetical and was generated for the purpose of the R tutorial, thus it is not relevant for any timeframe. \n",
    "\n",
    "Source: http://www.ats.ucla.edu/stat/sas/dae/logit.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 9.  What is the hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Past academic data will allow us to predict whether a UCLA grad school applicant will be admitted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 10.  What's the problem statement?\n",
    "\n",
    "> Using your answers to the above questions, write a well-formed problem statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \"Determine which applicants will be admitted to UCLA for graduate school, using academic record data included with the application (GRE score, GPA, and prestige of alma mater) based on data from UCLA's Logit Regression in R tutorial.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C.  Create an exploratory analysis plan by answering the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the answers to these questions haven't yet been covered in class yet, this section is optional.  This is by design.  By having you guess or look around for these answers will help make sense once we cover this material in class.  You will not be penalized for wrong answers but we encourage you to give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 11. What are the goals of the exploratory analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The goals of the exploratory analysis are to understand my data enough to feel comfortable moving forward with the creation of a predictive model. Steps involved in that include getting an idea of the range and distribution of the variable values, exploring any missing data (if any) and predict possible implications of that, exploring any outliers I find and possible explanations for their extreme values, and determining if there are any data points I would like to leave out of my model (either because of missing values or being an outlier). I will also plot variables against each other (one as Y, one as X) to see if any pair seems to be correlated, and calculate correlation coefficients for pairs that seem promising. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 12.  What are the assumptions of the distribution of data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The assumptions of the distribution of data are that the scores (gpa and gre) will be positive and falling within an expected range (0 to 4.0 and 0 to 800, respectively). The distributions are assumed to be a normal distribution or a slightly skewed distribution. The admit variable is assumed to be binary, and likely 0 will be a more common occurence than 1, but this is a guess. The prestige variable is assumed to be an integer from 1 to 4 (inclusive), likely with a normal or skewed distribution. \n",
    "\n",
    "The risks of the data are that there might not be enough data points (or enough of one value for admit) to properly train a model, that the list of features is too small to predict admission outcomes, or the presence of outliers and/or missing data might interfere with getting enough clean data for the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 13.  How will you determine the distribution of your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: I will plot a histogram and make a boxplot for each of the variables in my dataset, and use those graphs to get a sense of how the values of each of the variables are distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 14.  How might outliers impact your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Outliers, if present, might be an error (for instance, if an outlier was outside of the \"possible\" range of values for a variable), or they might be valid data points that represent an extraordinary circumstance. They might be deemed to be unrepresentative of the normal outcomes for this data set and thus excluded from analysis, leading me to have fewer data points for my predictive model, or they might be included and dominate the results in some way. I might try running the model with and without outliers included in the data to see if they skew the results tremendously, which would probably be bad, but if they are just a few data points out of many, I do not expect that to be the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 15.  How will you test for outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: I will compute the inter-quartile range (IQR) for each of the variables in the dataset, and calculate the range of \"typical\" data values, being from 1.5 * IQR less than the 1st Quartile value to 1.5 * IQR more than the 3rd Quartile value. Any data points with values outside of that range are outliers. I will also see if any data points have values outside the expected range for each variable, which might indicate a bad data point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 16.  What is colinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Colinearity is a state where two variables are correlated such that a change in one causes a predictable (close to proportional) change in the other variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 17.  How will you test for covariance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: I will calculate the correlation coefficient for any pair of variables that are graphed together and seem (visually) to have some degree of colinearity. That will give a quantitative measure of covariance. I will also make a correlation matrix to ensure I get a full picture of how all of the variables seem to be related. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 18.  What is your exploratory analysis plan?\n",
    "\n",
    "> Using the above information, write an exploratory analysis plan that would allow you or a colleague to reproduce your analysis one year from now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: My exploratory analysis plan is to follow the data exploration steps below:\n",
    "\n",
    ">1) Print basic statistics of the data (df.info() and df.describe()) to get a sense of how many data points we have, how many missing values might be in the data, and the basic statistics for that data\n",
    "\n",
    ">2) Plot histograms and boxplots for the variables to see the distributions and any outliers we might have\n",
    "\n",
    ">3) Look at any outliers and determine best action - leaving them in if they seem significant or removing them if they seem unrepresentative of the data or might be a result of error\n",
    ">4) Look at data points where any values are missing and determine if there's anything to be done besides dropping those rows. If no, drop those rows\n",
    "\n",
    ">5) Plot varibles against each other to get a sense of colinearity between them\n",
    "\n",
    ">6) Create correlation matrix\n",
    "\n",
    ">7) Plan which variables should be features in the model based on correlations. Likely all since few variables in this data set, but sometimes might not include all variables moving forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
